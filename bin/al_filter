#!/usr/bin/env python
import sys
import os
import logging
from contextlib import contextmanager
from decimal import Decimal, getcontext
getcontext().prec = 80

# Hack in order to avoid making this a python package
sys.path.append(os.path.dirname(
    os.path.abspath(sys.argv[0])) + os.sep + os.pardir + os.sep + "algolab")

import argparse
from pymongo import Connection

from algolab.simplify import anglereduce, rdp
from algolab.combine import anglecombine
from algolab.db import empty, dedup, delonelynize, new, copy, recalculate_distances
from algolab.cmdutil import log_progress, log_change, require_col, defaultparser
from algolab.simplify import simplify
from algolab.stations import cluster_stations


def main(zls, db):
    # The source collection
    rg_ = db["railway_graph"]

    # Collections for zoom level 8 - 16
    rgs = {i: db["railway_graph_%i" % i] for i in range(8, 17) + [30]}

    require = lambda x: require_col(db, x)

    if 30 in zls:
        with log_progress("Cleaning"):
            require("railway_graph")
            empty(rgs[30])

            copy(rg_, rgs[30])
            c0 = rgs[30].count()

            # This is the general cleaning step
            with log_progress("Removing lonely nodes"):
                delonelynize(rgs[30])
                c1 = rgs[30].count()
                log_change(c1, c0)

            with log_progress("Removing duplicates"):
                dedup(rgs[30])
                c2 = rgs[30].count()
                log_change(c2, c1)

            with log_progress("Recalculating all distances"):
                recalculate_distances(rgs[30])

    if 16 in zls:
        with log_progress("Zoom Level 16"):
            require(30)
            empty(rgs[16])

            # max tolerance in m
            epsilon = 20

            with log_progress("Applying RDP with eps=%f" % epsilon):
                simplify(rdp, rgs[30], rgs[16], [epsilon])
                zls.remove(16)
                log_change(rgs[16].count(), rg_.count())

    if 15 in zls:
        with log_progress("Zoom Level 15"):
            require(16)
            empty(rgs[15])

            # max tolerance in m
            epsilon = 2.5

            with log_progress("Applying RDP with eps=%f" % epsilon):
                simplify(rdp, rgs[16], rgs[15], [epsilon])
                log_change(rgs[15].count(), rgs[16].count())

    if 14 in zls:
        with log_progress("Zoom Level 14"):
            require(15)
            empty(rgs[14])

            # max angle in degrees
            epsilon = 15

            copy(rgs[15], rgs[14])

            with log_progress("Removing parallel tracks from railway_graph_14"):
                anglecombine(rgs[14], epsilon)
                c = rgs[14].count()
                log_change(c, rgs[15].count())

    if 12 in zls:
        with log_progress("Zoom Level 12"):
            require(30)
            empty(rgs[12])

            cluster_stations(rgs[30], db['stations'], db['clustered'])
            log_change(db['clustered'].count(), rgs[30].count())

            # max tolerance in m
            epsilon = 1.5

            with log_progress("Applying RDP with eps=%f" % epsilon):
                simplify(rdp, db['clustered'], rgs[12], [epsilon])
                zls.remove(12)
                log_change(rgs[12].count(), db['clustered'].count())

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Algorithm Filter Pipeline",
                                     parents=[defaultparser()])
    parser.add_argument("zl", type=int, nargs="+",
            help="zoom levels to generate a RG for")
    parser.add_argument("--no-progress", action="store_true", dest="np", default=False,
            help="don't print the progress")
    args = parser.parse_args()
    print args.loglevel

    db = Connection(args.host, args.port)[args.db]

    with log_progress("Overall process"):
        main(args.zl, db)
