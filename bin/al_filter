#!/usr/bin/env python
import sys
import os
import logging
from contextlib import contextmanager
from decimal import Decimal, getcontext
getcontext().prec = 80

# Hack in order to avoid making this a python package
sys.path.append(os.path.dirname(
    os.path.abspath(sys.argv[0])) + os.sep + os.pardir + os.sep + "algolab")

import argparse

from pymongo import Connection

from algolab.simplify import anglereduce, rdp
from algolab.combine import anglecombine
from algolab.db import create_rg, empty, dedup, delonelynize, new, copy
from algolab.cmdutil import log_progress, log_change, require_col
from algolab.simplify import simplify
from algolab.log import FORMAT as LOGGING_FORMAT


def main(zls, db):
    # The source collection
    rg_ = db["railway_graph"]

    # Collections for zoom level 8 - 16
    rgs = {i: db["railway_graph_%i" % i] for i in range(8, 17) + [0]}

    require = lambda x: require_col(db, x)

    if 0 in zls:
        require("railway_graph")
        empty(rgs[0])

        copy(rg_, rgs[0])
        c0 = rgs[0].count()

        # This is the general cleaning step
        with log_progress("Removing lonely nodes from railway_graph_0"):
            delonelynize(rgs[0])
            c1 = rgs[0].count()
            log_change(c1, c0)

        with log_progress("Removing duplicates from railway_graph_0"):
            dedup(rgs[0])
            c2 = rgs[0].count()
            log_change(c2, c1)

    if 16 in zls:
        require(0)

        with log_progress("Removing unnecessary points (zoom=16)"):
            simplify(rdp, rgs[0], rgs[16], [0.5])
            zls.remove(16)
            log_change(rgs[16].count(), rg_.count())

    if 15 in zls:
        require(16)
        epsilon = 5

        with log_progress("Applying RDP with eps=%f" % epsilon):
            simplify(rdp, rgs[16], rgs[15], [epsilon])
            log_change(rgs[15].count(), rgs[16].count())

    if 14 in zls:
        require(15)
        copy(rgs[15], rgs[14])

        with log_progress("Removing parallel tracks from railway_graph_14"):
            anglecombine(rgs[14], 25)
            c = rgs[14].count()
            log_change(c, rgs[15].count())


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Algorithm Filter Pipeline")
    parser.add_argument("zl", type=int, nargs="+",
            help="zoom levels to generate a RG for")
    parser.add_argument("--host", action="store", dest="host", default="127.0.0.1",
            type=str, help="host of the mongo database")
    parser.add_argument("--port", action="store", dest="port", default=27017,
            type=int, help="port of the mongo database")
    parser.add_argument("--db", action="store", dest="db", default="osm-data",
            type=str, help="name of the database")
    parser.add_argument("--no-progress", action="store_true", dest="np", default=False,
            help="don't print the progress")
    log_group = parser.add_mutually_exclusive_group()
    log_group.add_argument("-d", "--debug",
            action="store_const", const=logging.DEBUG,
            dest="loglevel", default=logging.INFO,
            help="print debugging messages")
    log_group.add_argument("-q", "--quiet",
            action="store_const", const=logging.WARNING,
            dest="loglevel", help="suppress most messages")
    args = parser.parse_args()
    logging.basicConfig(level=args.loglevel, format=LOGGING_FORMAT)

    db = Connection(args.host, args.port)[args.db]

    with log_progress("Overall process"):
        main(args.zl, db)
