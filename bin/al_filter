#!/usr/bin/env python
import sys
import os
import logging
from decimal import Decimal, getcontext
getcontext().prec = 80

# Hack in order to avoid making this a python package
sys.path.append(os.path.dirname(
    os.path.abspath(sys.argv[0])) + os.sep + os.pardir + os.sep + "algolab")

import argparse
from pymongo import Connection

from algolab.anglered import anglereduce
from algolab.rdp import rdp
from algolab.combine import anglecombine
from algolab.segment import Segmenter
from algolab.db import create_rg, empty, dedup, delonelynize, new
from algolab.util import log_progress, log_change
from algolab.simplify import simplify
from algolab.log import FORMAT as LOGGING_FORMAT


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Algorithm Visualization")
    parser.add_argument("zl", type=int, nargs="+",
            help="zoom levels to generate a RG for")
    parser.add_argument("--host", action="store", dest="host", default="127.0.0.1",
            type=str, help="host of the mongo database")
    parser.add_argument("--port", action="store", dest="port", default=27017,
            type=int, help="port of the mongo database")
    parser.add_argument("--db", action="store", dest="db", default="osm-data",
            type=str, help="name of the database")
    parser.add_argument("--no-progress", action="store_true", dest="np", default=False,
            help="don't print the progress")
    log_group = parser.add_mutually_exclusive_group()
    log_group.add_argument("-d", "--debug",
            action="store_const", const=logging.DEBUG,
            dest="loglevel", default=logging.INFO,
            help="print debugging messages")
    log_group.add_argument("-q", "--quiet",
            action="store_const", const=logging.WARNING,
            dest="loglevel", help="suppress most messages")
    args = parser.parse_args()
    logging.basicConfig(level=args.loglevel, format=LOGGING_FORMAT)

    db = Connection(args.host, args.port)[args.db]

    # The source collection
    rg_ = db["railway_graph"]

    # Collections for zoom level 8 - 16
    rgs = {i: db["railway_graph_%i" % i] for i in range(8, 17) + [0]}

    zls = list(args.zl)

    if 0 in zls:
        empty(rgs[0])

        with log_progress("Copying database to railway_graph_0"):
            for node in rg_.find():
                rgs[0].insert(dict(node))
            c0 = rgs[0].count()
            logging.info("Copied %i nodes" % rgs[0].count())

        # This is the general cleaning step
        with log_progress("Removing lonely nodes from railway_graph_0"):
            c1 = delonelynize(rgs[0])
            log_change(rgs[0].count(), c0)

        with log_progress("Removing duplicates from railway_graph_0"):
            c2 = dedup(rgs[0])
            c3 = rgs[0].count()
            log_change(c3, c0 - c1)

        with log_progress("Removing parallel tracks from railway_graph_0"):
            anglecombine(rgs[0], 10)
            log_change(rgs[0].count(), c3)

        zls.remove(0)

    if 16 in zls:
        empty(rgs[16])

        with log_progress("Removing unnecessary points (zoom=16)"):
            simplify(anglereduce, rgs[0], rgs[16], [179.99])
            zls.remove(16)
            log_change(rgs[16].count(), rg_.count())

    segmenter = Segmenter(rgs[16])

    for zl in reversed(sorted(zls)):
        if zl > 7:
            empty(rgs[zl])

            #epsilon = Decimal((0, (1, ), - int(1.6 * zl + 30)))
            epsilon = Decimal((0, (1, ), + 50))

            with log_progress("Applying RDP with epsilon=%s (zoom=%i)" % (
                epsilon.to_eng_string(), zl)):
                simplify(rdp, rgs[16], rgs[zl], [epsilon])
                log_change(rgs[zl].count(), rgs[16].count())
