#!/usr/bin/env python
import sys
import os
import logging
from contextlib import contextmanager
from functools import partial
from decimal import Decimal, getcontext
getcontext().prec = 80

# Hack in order to avoid making this a python package
sys.path.append(os.path.dirname(
    os.path.abspath(sys.argv[0])) + os.sep + os.pardir + os.sep + "algolab")

import argparse
from pymongo import Connection

from algolab.simplify import anglereduce, rdp
from algolab.combine import anglecombine
from algolab.db import empty, dedup, delonelynize, new, copy, recalculate_distances
from algolab.cmdutil import log_progress, log_change, require_col, defaultparser
from algolab.segment import StationESSegmenter
from algolab.simplify import simplify as simplify2
from algolab.stations import cluster_stations


def main(zls, db):
    require = lambda x: require_col(db, x)

    # The source collection
    rg_ = db["railway_graph"]

    # The station collections
    require("stations")
    stations = db["stations"]
    require("station_perimeter")
    stations_perimeter = db["station_perimeter"]
    station_ids = set(s["_id"] for s in stations.find())
    station_ids.update(s["_id"] for s in stations_perimeter.find())

    # the segmenter
    segmenter = partial(StationESSegmenter, station_ids)
    simplify = partial(simplify2, segmenter=segmenter)

    # Collections for zoom level 8 - 16
    rgs = {i: db["railway_graph_%i" % i] for i in range(8, 18)}

    ## Zoom Level 17 (Cleaning Step)
    if 17 in zls:
        with log_progress("Cleaning"):
            require("railway_graph")
            empty(rgs[17])

            copy(rg_, rgs[17])
            c0 = rgs[17].count()

            # This is the general cleaning step
            with log_progress("Removing lonely nodes"):
                delonelynize(rgs[17])
                c1 = rgs[17].count()
                log_change(c1, c0)

            with log_progress("Removing duplicates"):
                dedup(rgs[17])
                c2 = rgs[17].count()
                log_change(c2, c1)

            with log_progress("Recalculating all distances"):
                recalculate_distances(rgs[17])

    ## Zoom Level 16-12 (RDP)
    for zli, zl in enumerate([16, 15, 14, 13, 12], start=1):
        if zl in zls:
            with log_progress("Zoom Level %s" % zl):
                require(zl + 1)
                empty(rgs[zl])

                # max tolerance in m
                epsilon = zli * 1.3

                with log_progress("Applying RDP with eps=%f" % epsilon):
                    simplify(rdp, rgs[zl + 1], rgs[zl], [epsilon])
                    log_change(rgs[zl].count(), rgs[zl + 1].count())

    ## Zoom Level 11 (Clustering + RDP)
    if 11 in zls:
        with log_progress("Zoom Level 11"):
            require(12)
            empty(rgs[11])

            cluster_stations(rgs[12], stations, db['clustered'])
            log_change(db['clustered'].count(), rgs[12].count())

            # max tolerance in m
            epsilon = 6

            with log_progress("Applying RDP with eps=%f" % epsilon):
                simplify(rdp, db['clustered'], rgs[11], [epsilon])
                zls.remove(11)
                log_change(rgs[11].count(), db['clustered'].count())

    ## Zoom Level 10 (Anglecombine + RDP)
    if 10 in zls:
        with log_progress("Zoom Level 10"):
            require(11)
            empty(db["parallel"])
            empty(rgs[10])

            # max tolerance in degrees
            epsilon = 10

            with log_progress("Applying Anglecombine with eps=%f" % epsilon):
                copy(rgs[11], db["parallel"])

                anglecombine(db["parallel"], epsilon, keep_ids=station_ids)
                log_change(db["parallel"].count(), rgs[11].count())

            epsilon = 6
            with log_progress("Applying RDP with eps=%f" % epsilon):
                simplify(rdp, db["parallel"], rgs[10], [epsilon])
                log_change(rgs[10].count(), db["parallel"].count())

    ## Zoom Level 9-8 (RDP)
    for zli, zl in enumerate([9, 8], start=1):
        if zl in zls:
            with log_progress("Zoom Level %s" % zl):
                require(zl + 1)
                empty(rgs[zl])

                # max tolerance in m
                epsilon = zli * 10

                with log_progress("Applying RDP with eps=%f" % epsilon):
                    simplify(rdp, rgs[zl + 1], rgs[zl], [epsilon])
                    log_change(rgs[zl].count(), rgs[zl + 1].count())

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Algorithm Filter Pipeline",
                                     parents=[defaultparser()])
    parser.add_argument("zl", type=int, nargs="*",
            help="zoom levels to generate a RG for")
    parser.add_argument("--no-progress", action="store_true", dest="np", default=False,
            help="don't print the progress")
    parser.add_argument("--all-zoomlevels", action="store_true", dest="all",
                        help="generate for all zoomlevels (8-17)")
    args = parser.parse_args()
    if args.all:
        args.zl = range(8, 18)
    else:
        assert len(args.zl) > 0, "Specify at least one zoomlevel or use '--all' parameter"

    db = Connection(args.host, args.port)[args.db]

    with log_progress("Overall process"):
        main(args.zl, db)
